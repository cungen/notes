#Area/AI/Eval 
## ä»‹ç»

llamaå®˜ç½‘æ¦œå•ï¼š[https://www.llama.com/](https://www.llama.com/)

![[Pasted image 20241212181556.png|600]]

Model Cardé‡Œä¹Ÿæœ‰æˆç»©ç›¸å…³çš„æè¿°

[https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)

å…·ä½“çš„è¯„æµ‹æ•°æ®è§ï¼š[https://huggingface.co/datasets/meta-llama/Llama-3.3-70B-Instruct-evals](https://huggingface.co/datasets/meta-llama/Llama-3.3-70B-Instruct-evals)

åŒ…å«äº†12ä¸ªtasksï¼šhuman_eval, mmlu_pro, gpqa_diamond, ifeval__loose, mmlu__0_shot__cot, nih__multi_needle, mgsm, math_hard, bfcl_chat, ifeval__strict, math, mbpp_plus.

**Base PreTrained Model**

![[Pasted image 20241212181624.png|600]]

# PreTrain BaseModel
## Llama 3.1

[Llama Eval Detail](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/eval_details.md)

| Dataset Name    | few-shot | cot? | max_out_len | remarks           | ç°çŠ¶æ•°æ®é›†æƒ…å†µ |
| --------------- | -------- | ---- | ----------- | ----------------- | ------- |
| agieval_english | 0        | âŒ    | 10          | default settings  |         |
| arc_challenge   | 25       | -    | -           | ppl               |         |
| bbh             | -        | -    | -           |                   |         |
| boolq           | 0        | -    | -           | ppl               |         |
| commonseqa      | 8        | âœ…    | -           | ppl æˆ‘ä»¬çš„ä¸åŒ…å«cot     |         |
| drop            | 3        | âœ…    | 32k         | gen               |         |
| mmlu            | 5        | -    | -           | ppl               |         |
| mmlu_pro        | 5        | âœ…    | 512         | gen               |         |
| quac            | 1        | -    | 32          | gen - f1          |         |
| squad           | 1        | âŒ    | 32          | gen - exact match |         |
| triviaqa_wiki   | 5        | -    | 24          | gen - exact match |         |
| winogrande      | 5        | -    | -           | ppl               |         |
# PostTrain ChatModel

## Llama3.3

è¯¦è§ï¼š[https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/eval_details.md](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/eval_details.md)

| Dataset Name    | few-shot | cot? | max_out_len | remarks           | ç°çŠ¶æ•°æ®é›†æƒ…å†µ |
| --------------- | -------- | ---- | ----------- | ----------------- | ------- |
| agieval_english | 0        | âŒ    | 10          | default settings  |         |
| arc_challenge   | 0        | -    | 100         | gen               |         |
| bbh             | -        | -    | -           | -                 |         |
| boolq           | -        | -    | -           | gen               |         |
| commonseqa      | 7        | -    | -           | gen               |         |
| drop            | 3        | âœ…    | 32k         | gen               |         |
| mmlu            | 5        | âœ…    | 1024        | gen               |         |
| mmlu_pro        | 5        | âœ…    | 1024        | gen               |         |
| quac            | -        | -    | -           | gen - f1          |         |
| squad           | 1        | âŒ    | 32          | gen - exact match |         |
| triviaqa_wiki   | 5        | -    | 24          | gen - exact match |         |
| winogrande      | 5        | -    | -           |                   |         |
### IFEval âœ…

**PostTrain Model**

- Default Setting å’Œç°æœ‰å¹³å°ä¸€è‡´ âœ…

### HumanEval âœ…

- æ— ç‰¹æ®Šè¯´æ˜

### MBPP EvalPlus â“

**PostTrain Model**

- 0-shot â€” ç°æœ‰å¹³å°æ˜¯æœ‰shotçš„ï¼Œå¯ä»¥è·‘ä¸‹è¯•è¯•ï¼Œæ•°æ®é›†åç§°æ˜¯ mbpp_plus_gen

### Math

ğŸ˜«Â Hard

**PreTrain Model**

- 4-shot max_out_len=512

**PostTrain Model**

- 0-shot cot max_out_len=5120 post process

### GPQA Diamond(subset)

âš ï¸Â æ·»åŠ é…ç½®

**PostTrain Model**

- 0-shot cot exact match max_out_len=2048

### BFCL v2

ğŸ˜†Â New

### NIH/Multi-needle

ğŸ˜­

0-shot context lengths 2000 ~ 131072 in 10 intervals max_out_len=256

### MGSM

- 

## é’ˆå¯¹BaseModel

æ•°æ®é›†æœ‰ï¼šMMLUã€AGIEval Englishã€ARC-Challengeã€SQuADã€QuACã€DROPã€Needle in Haytack

![[Pasted image 20241212181624.png|600]]

è²Œä¼¼åªæœ‰Needle in Haystackæ²¡æœ‰ï¼Œä½†è¿™ä¸ªåˆ†æ¯”è¾ƒå¥‡æ€ªï¼Œå¯ä»¥æš‚ä¸è€ƒè™‘ï¼Œ1Bçš„96åˆ†ï¼Œ3Bå’Œ8Bçš„åªæœ‰1åˆ†ï¼Ÿ

- [x] mmlu â€” mmlu_ppl
- [x] AGIEval â€” hh_agieval_english_gen
    - [x] è‡ªå®šä¹‰5-shot randomly
- [x] ARC-Challenge â€” ARC_c_few_shot_ppl
- [x] SQuAD
    - [x] è‡ªå®šä¹‰1-shot randomly
- [ ] QuAC
- [x] DROP 5-shot cot