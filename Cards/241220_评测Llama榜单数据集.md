#Area/AI/Eval 
## ‰ªãÁªç

llamaÂÆòÁΩëÊ¶úÂçïÔºö[https://www.llama.com/](https://www.llama.com/)

![[Pasted image 20241212181556.png|600]]

Model CardÈáå‰πüÊúâÊàêÁª©Áõ∏ÂÖ≥ÁöÑÊèèËø∞
[https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)

‰ΩÜÁî±‰∫éÂêÑLlamaÁâàÊú¨3.1~3.3‰ΩøÁî®ÁöÑËØÑÊµãÈõÜ‰∏çÂêåÔºåPreTrainÂíåPostTrainÊâÄ‰ΩøÁî®ÁöÑ‰πü‰∏ç‰∏ÄÊ†∑ÔºåÊâÄ‰ª•Êàë‰ª¨==Âè™ÂØπÈΩêLlama3.1ÁöÑPreTrainÂèäLlama3.3ÁöÑPostTrainÊï∞ÊçÆÈõÜ==
# PreTrain BaseModel
## Llama 3.1

ËØÑÊµãÊï∞ÊçÆÔºö[Llama-3.1-70B-evals](https://huggingface.co/datasets/meta-llama/Llama-3.1-70B-evals/tree/main/Llama-3.1-70B-evals)
Êï∞ÊçÆÈõÜËØ¥ÊòéÔºö[Llama Eval Detail](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/eval_details.md)
[3.1 ModelCard](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)

> "-"Ë°®Á§∫Êú™ÊòéÁ°ÆËØ¥Êòé
> ‰∏Ä‰∫õÊï∞ÊçÆÈõÜÂÆö‰πâÂú®eval detail‰∏≠Âíåmodel card‰∏≠Â¶ÇÊûú‰∏ç‰∏ÄËá¥Ôºå‰ª•ModelCard‰∏≠ÁöÑË°®Ê†º‰∏∫ÂáÜ

| type                  | Dataset Name    | few-shot | cot? | max_out_len | remarks           | Áé∞Áä∂Êï∞ÊçÆÈõÜÊÉÖÂÜµÂü∫‰∫éOpenCompass                             |
| --------------------- | --------------- | -------- | ---- | ----------- | ----------------- | ------------------------------------------------ |
| General               | agieval_english | 3-5      | ‚ùå    | 10          | default settings  | ‚úÖ hh_agieval_english_genÔºåÊ∑ªÂä†few-shot              |
| General               | arc_challenge   | 25       | -    | -           | ppl               | ‚úÖ ARC_c_few_shot_pplÔºå‰ΩÜÂè™Êúâ5-shot                   |
| General               | bbh             | 3        | -    | -           |                   | ‚úÖ bbh_gen                                        |
| Reading comprehension | boolq           | 0        | -    | -           | ppl               | ‚úÖ superglue_boolq_few_shot_ppl Âä†‰∫Üfew-shotÔºåÊïàÊûúÊõ¥Â•Ω‰∏Ä‰∫õ |
| General               | commonseqa      | 8        | ‚úÖ    | -           | ppl Êàë‰ª¨ÁöÑ‰∏çÂåÖÂê´cot     | ‚úÖ commonsenseqa_ppl                              |
| Reading comprehension | drop            | 3        | ‚úÖ    | 32k         | gen               | ‚úÖ drop_gen ‰∏ä‰∏ãÊñáÈïøÂ∫¶‰ΩøÁî®ÈªòËÆ§ÔºåÊ≤°Êúâ32k                       |
| General               | mmlu            | 5        | -    | -           | ppl               | ‚úÖ mmlu_ppl                                       |
| General               | mmlu_pro        | 5        | ‚úÖ    | 512         | gen               | ‚úÖ hh_mmlu_pro_gen Âä†cotÂíåmax_out_len               |
| Reading comprehension | QuAC            | 1        | -    | 32          | gen - f1          | ‚úÖ hh_quac_gen ‰ªÖÂ∞ùËØïÂØπÈΩêÂÖ∂‰∏≠ÁöÑspanÁª¥Â∫¶                     |
| Reading comprehension | SQuAD           | 1        | ‚ùå    | 32          | gen - exact match | ‚úÖ hh_squad_mini_gen Ê∑ªÂä†few-shot                   |
| Knowledge reasoning   | triviaqa_wiki   | 5        | -    | 24          | gen - exact match | ‚úÖ ÈúÄÂèñÂ≠êÈõÜ hh_triviaqa_wiki_gen                      |
| General               | winogrande      | 5        | -    | -           | ppl               | ‚úÖ hh_winogrande_5shot_mini_ppl                   |
# PostTrain ChatModel

## Llama3.3

ËØÑÊµãÊï∞ÊçÆÔºö[Llama-3.3-70B-Instruct-evals](https://huggingface.co/datasets/meta-llama/Llama-3.3-70B-Instruct-evals/tree/main/Llama-3.3-70B-Instruct-evals)
Êï∞ÊçÆÈõÜËØ¥ÊòéÔºö[eval_details.md](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/eval_details.md)
[3.3 ModelCard](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)

>"-"Ë°®Á§∫Êú™ÊòéÁ°ÆËØ¥Êòé
### [Llama website benchmark](https://www.llama.com/)

| Category              | Dataset Name                                    | Few-Shot Num | CoT | Max Out Len | Current State                             |
| --------------------- | ----------------------------------------------- | ------------ | --- | ----------- | ----------------------------------------- |
| General               | mmlu_0_shot_cot                                 | 0            | ‚úÖ   | 1024        | ‚úÖ hh_mmlu_0shot_gen max_out_len Âè™Êúâ 256    |
| General               | mmlu_pro                                        | 5            | ‚úÖ   | 1024        | ‚úÖ hh_mmlu_pro_gen Âä†cotÂíåmax_out_len        |
| Instruction Following | IFEval                                          | -            | -   | -           | ‚úÖ IFEval_gen                              |
| Code                  | human_eval                                      | 0            | -   | 1024        | ‚úÖ humaneval_gen                           |
| Code                  | mbpp_plus                                       | -            | -   | -           | ‚úÖ mbpp_gen                                |
| Math                  | MATH                                            | 0            | ‚úÖ   | 5120        | ‚úÖ hh_llama_math_gen max_out_len 2048      |
| Math                  | MATH_hard                                       | 0            | ‚úÖ   | 5120        | ‚úÖ hh_llama_math_hard_gen max_out_len 2048 |
| Reasoning             | GPQA Diamond                                    | 0            | ‚úÖ   | 2048        | ‚úÖ gpqa_gen                                |
| Tool use              | Berkeley Function Calling Leaderboard (BFCL) v2 | -            | -   | -           | üõ†                                        |
| Long context          | NIH/Multi-needle                                | 0            | ‚ùå   | 256         |                                           |
| Multilingual          | MGSM                                            | 0            | ‚úÖ   | 2048        | ‚úÖ mgsm_gen                                |

### [Eval Detail Datasets](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/eval_details.md)

| Dataset Name      | Few-Shot Num | CoT | Max Out Len | Current State                  |
| ----------------- | ------------ | --- | ----------- | ------------------------------ |
| TLDR9+            | 1            | ‚ùå   | 512         |                                |
| Open-Rewrite      | 0            | ‚ùå   | 512         |                                |
| ARC-Challenge     | 25           | ‚ùå   | 100         | ‚úÖ ARC_c_few_shot_pplÔºå‰ΩÜÂè™Êúâ5-shot |
| AGIEval English   | -            | -   | 10          | ‚úÖ hh_agieval_english_gen       |
| SQuAD             | 1            | ‚ùå   | 32          | üõ† ÈúÄÊ∑ªÂä†few-shot                 |
| QuAC              | 1            | ‚ùå   | 32          |                                |
| DROP              | 3            | ‚ùå   | 32          | ‚úÖ drop_gen                     |
| GSM8K             | 8            | ‚úÖ   | 1024        | ‚úÖ gsm8k_gen max_out_len 512    |
| InfiniteBench     | 0            | ‚ùå   | 20          |                                |
| Multilingual MMLU | 5            | ‚ùå   | 10          |                                |
| Nexus             | -            | -   | -           |                                |
| RULER             | -            | -   | -           | ‚úÖ                              |
| MMMU              | 0            | ‚úÖ   | 2048        |                                |
| MMMU-Pro standard | 0            | ‚ùå   | 2048        |                                |
| MMMU-Pro vision   | 0            | ‚ùå   | 2048        |                                |
| AI2D              | 0            | ‚ùå   | 400         |                                |
| ChartQA           | 0            | ‚úÖ   | 512         |                                |
| DocVQA            | 0            | ‚ùå   | 512         |                                |
| VQAv2             | 0            | ‚ùå   | 25          |                                |
| MathVista         | 0            | ‚ùå   | 2048        |                                |
